{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c71b2e",
   "metadata": {},
   "source": [
    "### <font color='darkred'>IA Aplicado a Finanças</font>\n",
    "### <font color='darkgreen'>Prever inadimplência com base em Análise de Crédito</font>   \n",
    "### <font color='darkblue'>Parte 1 - Treino e Teste do modelo</font>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e740707",
   "metadata": {},
   "source": [
    "Inadimplência com base no histórico de crédito (dados fictícios) refere-se à situação em que um indivíduo ou entidade não cumpre suas obrigações financeiras, como o pagamento de uma dívida e esse comportamento é registrado em seu histórico de crédito.\n",
    "\n",
    "As instituições financeiras usam o histórico de crédito para prever a probabilidade de inadimplência de um potencial mutuário. Se um indivíduo tem um histórico de inadimplências anteriores, ele é considerado de maior risco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011d3a7",
   "metadata": {},
   "source": [
    "O  objetivo desse projeto é aplicar técnicas de  Inteligência  Artificial  para desenvolver um modelo preditivo focado na identificação precoce de potenciais inadimplentes. \n",
    "\n",
    "Com base em características do histórico de crédito da base de clientes de uma empresa, o modelo é treinado para detectar padrões e tendências que tipicamente levam à inadimplência. O objetivo é proporcionar às instituições financeiras uma ferramenta robusta e precisa que as ajude a tomar decisões mais informadas no processo de concessão de crédito, minimizando riscos e fortalecendo a saúde financeira da empresa. \n",
    "\n",
    "Ao  longo  do  projeto,  também  enfatizamos  a  importância  da  interpretabilidade  do modelo, garantindo que as decisões tomadas pela IA possam ser compreendidas e justificadas perante as partes interessadas. Os dados usados no projeto são fictícios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb4cbf",
   "metadata": {},
   "source": [
    "### <font color='darkred'>Instalando e Carregando Pacotes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb255e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2306b385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp39-cp39-win_amd64.whl (203.0 MB)\n",
      "     -------------------------------------- 203.0/203.0 MB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx in c:\\users\\miche\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\miche\\anaconda3\\lib\\site-packages (from torch) (2022.7.1)\n",
      "Collecting typing-extensions>=4.8.0\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\miche\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Collecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "     ---------------------------------------- 6.2/6.2 MB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Installing collected packages: typing-extensions, sympy, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.10.1\n",
      "    Uninstalling sympy-1.10.1:\n",
      "      Successfully uninstalled sympy-1.10.1\n",
      "Successfully installed sympy-1.13.1 torch-2.5.1 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea92c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd # receb os dados e manipula através de um dataframe\n",
    "import torch # framework pytorch para redes neurais artificiais\n",
    "import torch.nn as nn # Cria as camadas da rede neural\n",
    "import torch.optim as optim # otimiza o modelo.\n",
    "from sklearn.model_selection import train_test_split # divide dados em treino e teste\n",
    "from sklearn.preprocessing import StandardScaler # padroniza os dados\n",
    "from joblib import dump # para fazer o dump do padronizador (o Scaler) - salvar em disco durante o treinamento\n",
    "\n",
    "# Quando você ajusta o StandardScaler nos dados, ele aprende a média e o desvio padrão de cada feature. \n",
    "# Salvando esse objeto ajustado, você pode reutilizar exatamente as mesmas configurações para padronizar novos dados \n",
    "# (como dados de teste ou novos dados de produção), garantindo consistência no pré-processamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6bf33",
   "metadata": {},
   "source": [
    "O PyTorch (ou simplesmente torch no Python) é uma biblioteca de código aberto para aprendizado de máquina, amplamente usada para construir e treinar redes neurais e realizar tarefas de aprendizado profundo (deep learning). Criado pelo Facebook, ele é especialmente popular na comunidade de pesquisa em inteligência artificial e aprendizado profundo devido à sua flexibilidade e facilidade de uso.\n",
    "\n",
    "**Principais Características do PyTorch**\n",
    "\n",
    "Tensores: PyTorch trabalha com tensores, que são essencialmente arrays multidimensionais (como as matrizes do NumPy) e formam a base de qualquer cálculo em aprendizado profundo. Tensores podem ser processados tanto na CPU quanto na GPU (se você tiver uma placa gráfica compatível), o que acelera os cálculos e é muito útil para redes neurais profundas.\n",
    "\n",
    "Autograd (Diferenciação Automática): PyTorch possui uma funcionalidade de autograd, que calcula automaticamente as derivadas durante o treinamento de redes neurais. Isso é fundamental, pois a maioria dos algoritmos de aprendizado profundo usa a retropropagação (backpropagation) para ajustar os pesos dos neurônios, minimizando o erro entre as previsões e os valores reais.\n",
    "\n",
    "Construção Dinâmica de Redes Neurais: Diferente de outras bibliotecas mais antigas, como o TensorFlow (na versão 1.x), o PyTorch permite definir e modificar redes neurais de forma \"dinâmica\". Isso significa que você pode construir uma rede neural enquanto executa o código, o que é útil para depurar e experimentar novas ideias.\n",
    "\n",
    "Modelos Pré-Treinados e Transfer Learning: Embora torch em si seja o núcleo, com a extensão torchvision (para visão computacional), você pode acessar modelos de redes neurais pré-treinados. Esses modelos são ideais para realizar transfer learning, ou seja, ajustar um modelo pré-treinado para uma tarefa específica.\n",
    "\n",
    "Ampla Adoção e Comunidade Ativa: Devido à sua popularidade, o PyTorch tem uma enorme comunidade e muitos recursos educacionais disponíveis. Isso torna mais fácil encontrar tutoriais, documentação e até bibliotecas adicionais para expandir suas funcionalidades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5628f1ba",
   "metadata": {},
   "source": [
    "**Exemplos de Uso do PyTorch**\n",
    "\n",
    "- Reconhecimento de Imagens: Redes neurais convolucionais (CNNs) são amplamente usadas em visão computacional para classificar imagens ou detectar objetos. PyTorch facilita a construção dessas redes.\n",
    "\n",
    "\n",
    "- Processamento de Linguagem Natural (NLP): Com redes como LSTMs e Transformers, o PyTorch é muito usado para análise de texto, como tradução automática, análise de sentimentos e chatbots.\n",
    "\n",
    "\n",
    "- Séries Temporais e Previsão: Modelos como LSTMs e RNNs no PyTorch são usados para prever séries temporais, como preços de ações ou padrões climáticos.\n",
    "\n",
    "\n",
    "- Criação de Algoritmos de Recomendação: Redes neurais podem ser treinadas para recomendar produtos com base no histórico do usuário."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0bb51",
   "metadata": {},
   "source": [
    "**torch.nn:**\n",
    "\n",
    "- Esse módulo fornece componentes essenciais para construir redes neurais, como camadas (layers) e funções de ativação.\n",
    "- Ele inclui classes como nn.Linear (para camadas totalmente conectadas), nn.Conv2d (para camadas convolucionais em redes neurais convolucionais) e funções de ativação como nn.ReLU.\n",
    "- torch.nn é fundamental para definir a estrutura das redes neurais, organizando as camadas e configurando os parâmetros que serão ajustados durante o treinamento.\n",
    "\n",
    "\n",
    "**torch.optim:**\n",
    "\n",
    "- Esse módulo fornece algoritmos de otimização, como SGD (Stochastic Gradient Descent), Adam, Adagrad, entre outros.\n",
    "- Ele permite configurar a forma como os pesos da rede neural são atualizados durante o treinamento, controlando o processo de ajuste para minimizar a função de perda.\n",
    "- Por exemplo, torch.optim.Adam é um otimizador popular para treinamento de redes neurais devido à sua eficácia em ajustar os pesos de forma eficiente.\n",
    "\n",
    "\n",
    "**Esses dois módulos são muito usados juntos em aprendizado profundo: torch.nn para construir a estrutura da rede neural e torch.optim para treinar a rede ajustando os pesos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cad845b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Michelle Bouhid\n",
      "\n",
      "sklearn : 1.3.0\n",
      "joblib  : 1.4.2\n",
      "torch   : 2.5.1\n",
      "platform: 1.0.8\n",
      "pandas  : 1.5.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Michelle Bouhid\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdfcc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o arquivo CSV\n",
    "df = pd.read_csv(\"dados/clientes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b695d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os dados em treinamento e teste\n",
    "X = df[['idade', 'salario', 'historico_credito', 'emprestimos_ativos']].values  #variavel de entrada\n",
    "y = df['inadimplente'].values  #variavel de saida\n",
    "\n",
    "# poderia prever qtos emprestimos ativos o cliente pode ter no futuro, variavel de saida (Y) seria emprestimos\n",
    "# teria que usar outro modelo pq nesse a saida é 0 ou 1 e inadimplente seria variável de entrada\n",
    "# teria q verificar se a variavel X é relevante para prever Y, (mas os dados foram produzidos para o modelo.)\n",
    "# temos que usar a tecnica de seleção em variáveis X pra saber se é relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "476db6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir em dados de treino e teste\n",
    "# usou 20% pra teste e 80% treino\n",
    "# o random state é pra produzir o mesmo resultado de aula, na versão final pode remover\n",
    "# precisa dividir em treino e teste para avaliar o modelo sabendo Y na parte de teste\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092dc321",
   "metadata": {},
   "source": [
    "### <font color='darkred'>Pré Processamento dos Dados</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e8bff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se não padronizar, durante as operações matematicas a variavel/atributo que tem uma escala maior, \n",
    "# ganha mais relevancia para previsão da variavel alvo, impactando a performance do modelo, deixando desequilibrando.\n",
    "\n",
    "# Pré-processar os dados (normalização)\n",
    "scaler = StandardScaler() #cria o objeto scaler\n",
    "\n",
    "# pega o objeto \"scaler\" (Que esta na memória do computador) e aplica o metodo fit_transform nos dados de treino\n",
    "# metodo fit aprende o padrão nos dados - treina o modelo\n",
    "# usa o transform para aplicar a padronização no dados\n",
    "X_train = scaler.fit_transform(X_train) \n",
    "\n",
    "# no dados de teste aplica o metodo transform somente, não usa o fit, porque não vai treinar, vai testar\n",
    "# tem que aplicar o padronizador (scaler) tb nos dados de teste.\n",
    "# Tudo que aplicar em dados de treino aplica nos dados de teste, menos o metodo fit!\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5c19591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar o tipo e shape dos dados, pytorch espera receber dados em formato de \"tensor\"\n",
    "# Tensor é um estrutura de dados do Pytorch, como dataframe no Pandas por ex., ou array no Numpy.\n",
    "\n",
    "# Vamos colocar todos os valores como TIPO decimal (float), para não perder precisão nos calculos. (FloatTensor)\n",
    "# mesmo idade sendo inteiro, pra não ter arredondamento nas operaçoes matematicas, ganha precisão\n",
    "\n",
    "# unsqueeze tb é uma transformação no SHAPE dos dados pra o Pytorch, porque ele espera receber os dados como tensor \n",
    "# mas o tensor vem no formato de lista e o unsqueeze quebra a lista e coloca no shape que o Pytorch quer\n",
    "\n",
    "# o x_train é uma matriz que é um tensor e o y_train é uma lista de valores \n",
    "# não pode entregar com mais de 1 dimensão o unsqueeze deixa a lista com 1 dimensão\n",
    "X_train = torch.FloatTensor(X_train) # X_train é uma matriz que é um tensor\n",
    "y_train = torch.FloatTensor(y_train).unsqueeze(1) #Y_train, não é um mtz, é uma lista, precisa entregar somente 1 dimensão\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(y_test).unsqueeze(1) # Precisa quebrar a dimensionalidade de Y e entregar ao torch com 1 dimensão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76455cf8",
   "metadata": {},
   "source": [
    "### <font color='darkred'>Construir a arquitetura do modelo de Deep Learning</font>\n",
    "\n",
    "- Deep Learning Book : \n",
    "https://www.deeplearningbook.com.br/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "470a6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo  a Arquitetura do modelo de Deep Learning\n",
    "\n",
    "# Usa a \"Classe Module\" pronta no Torch, e a arquitetura será criada herdando as caracteristicas\n",
    "\n",
    "# Define a classe ModeloNN (filha) herdando de nn.Module (Mãe) \n",
    "\n",
    "# Construtor, qdo criar um objeto dessa classe(instancia da classe), tudo que está dentro do Construtor será\n",
    "# executado para inicialização do objeto da classe.(Criado em Model - In12)\n",
    "\n",
    "# Criando a classe Python que define a arquitetura do modelo - Programação orientada a objetos\n",
    "# A classe ModeloNN herda caracteristacas da classe mãe \"Module\", que pertence ao \"nn\" do torch. (neural network)\n",
    "# detalhes mais técnicos de implementação de hardware está definido no \"Module\" do framework Pytorch que \n",
    "# são herdados para a classe filha \"ModeloNN\"\n",
    "\n",
    "class ModeloNN(nn.Module): \n",
    "\n",
    "    # dentro da classe filha tem 2 métodos(fçs dentro da classe): Método Construtor __init__ e forward\n",
    "    # Método Construtor __init__ => cria e inicializa as camadas do modelo.\n",
    "    # forward => Executa as camadas\n",
    "    \n",
    "    # Método construtor para inicializar a classe - \n",
    "    def __init__(self, input_dim): #recebe o input_dim de X (entrada) = 4 colunas (dimensão de entrada)\n",
    "\n",
    "        # Chama o construtor da classe pai (nn.Module), inicializando as camadas do nosso modelo\n",
    "        super(ModeloNN, self).__init__() \n",
    "        \n",
    "        # Define a primeira camada totalmente conectada (entrada: input_dim, saída: 128)\n",
    "        # fc - fully conected 1,2,3,4 , nesse caso, camada lineares\n",
    "        # No final entra uma camada de ativação sigmoide, \n",
    "        # O sigmoide que pega oq receber e converte para uma saída entre 0 e 1, interpreta como probabilidade\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        \n",
    "        # Define a segunda camada totalmente conectada (entrada: 128, saída: 64)\n",
    "        # O numero de operações matematicas(128) vai influenciar o numero de operações matematicas entre as camadas\n",
    "        self.fc2 = nn.Linear(128, 64) #neuronios matemáticos 128, 64\n",
    "        \n",
    "        # Define a terceira camada totalmente conectada (entrada: 64, saída: 32)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        \n",
    "        # Define a quarta camada totalmente conectada (entrada: 32, saída: 1)\n",
    "        # Veio diminuido a saída ate chegar em 1 saída: Inadimplente ou nao\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        \n",
    "        # Define a função de ativação Sigmóide\n",
    "        # converte em saida que podemos interpretar como probabilidade, valor entre 0 e 1\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "  # Método forward para propagação para frente da rede\n",
    "    # Agora no método foward as camadas criadas acima serão executadas\n",
    "    # forward recebe x, que são os dados de entrada nas proximas camadas\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Pega o resultado e passa pela fç ReLU após a primeira camada totalmente conectada\n",
    "        # ReLU fç de ativação, exclui resultados negativos, gera 0\n",
    "        # REsolve problemas de linearidade nos dados, não pode deixar passar velores negativos\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        \n",
    "        # Aplica ReLU após a segunda camada totalmente conectada\n",
    "        # pegando o x da camada acima e passando como argumento na camada 2, fc2\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        \n",
    "        # Aplica ReLU após a terceira camada totalmente conectada\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        \n",
    "        # Aplica Sigmóide após a quarta camada totalmente conectada\n",
    "        # depois de passar pelas camadas, entrega a sigmoide para obeter um resultado entre 0 e 1\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        \n",
    "        # Retorna a saída\n",
    "        return x      \n",
    "\n",
    "    # As camadas intermediárias vão aprendendo o padrão que relaciona as variaveis de entrada e saida nos dados.\n",
    "    # se existir o padrão de relacionamento*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c5cc0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o modelo - especificação geral do modelo, é a casca do modelo.\n",
    "# X_train conjunto de dados de entradas recebe shape, que busca nº de linhas (0) e colunas (1)\n",
    "# temos 4 colunas em X_train, mas vamos automatizar o codigo ao inves de colocar o 4 direto como parâmetro\n",
    "\n",
    "# X_train.shape[1], é o input_dim, definido lá no metodo construtor, \n",
    "\n",
    "model = ModeloNN(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0f9e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a função de erro (fç alvo)\n",
    "# BCELoss é bastante usada em modelos de classificação binária\n",
    "# Calcula a media da diferença dentre o valor real e a previsão do modelo na variavel de saída: Inadimplente 0 ou 1\n",
    "criterion = nn.BCELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d0c492f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando o Treinamento...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir o otimizador\n",
    "# vamos otimizar a função de erro, minimizando o erro calculado na função BCELoss\n",
    "# Usa o algoritmo back propagation, para chegar ao valor otimizado do erro, ié, calcula a derivada\n",
    "# learning rate (lr) - taxa de aprendizado, que valor de hiperparêmetro que visa controlar a velocidade de treino\n",
    "# Adam - algoritmo de otimização pra aplicar o back propagation, ajusta os pesos em cada passada, para minimizar a perda\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001) \n",
    "\n",
    "\n",
    "print('\\nIniciando o Treinamento...\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56323185",
   "metadata": {},
   "source": [
    "Binary Cross Entropy Loss(Perda de Entropia Cruzada Binária) é uma função comumente usada  em  problemas  de  **classificação  binária**  ou  em  situações  em  que  se  deseja  modelar  a probabilidade de um evento ser verdadeiro ou falso.\n",
    "\n",
    "A BCE é usada para calcular o erro do modelo e o objetivo em Deep Learning é exatamente minimizar a função de erro. Esta é a fórmula da função:\n",
    "\n",
    "$$\n",
    "\\text{BCE}(\\hat{y}, y) = - y \\cdot \\log(\\hat{y}) - (1 - y) \\cdot \\log(1 - \\hat{y})\n",
    "$$\n",
    "\n",
    "\n",
    "Aqui  y  representa  o  label  real  e  $\\hat{y}$  representa  a  previsão  feita  pelo  modelo. A  função nn.BCELoss()  do  PyTorch  calcula  automaticamente  a  média  (ou  a  soma,  dependendo  do argumento  reduction  fornecido)  da  Binary  Cross  Entropy  entre  as  previsões  e  os  rótulos verdadeiros fornecidos.\n",
    "\n",
    "Confira aqui a documentação oficial da função:https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html\n",
    "\n",
    "\n",
    "\n",
    "A **Binary Cross Entropy** (BCE) é uma medida que avalia a diferença entre a probabilidade prevista pelo modelo ($\\hat{y}$) e o valor real ($y$), onde:\n",
    "\n",
    "- $y \\in \\{0, 1\\}$: Os rótulos verdadeiros.\n",
    "- $\\hat{y} \\in [0, 1]$: A probabilidade prevista para a classe positiva.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Fórmula Matemática Geral\n",
    "O **BCELoss** é calculado para cada amostra e pode ser representado como:\n",
    "\n",
    "$$\n",
    "\\text{BCELoss} = - \\frac{1}{N} \\sum_{i=1}^N \\left[ y_i \\cdot \\log(\\hat{y}_i) + (1 - y_i) \\cdot \\log(1 - \\hat{y}_i) \\right]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Onde:\n",
    "\n",
    "- $N$: Número total de amostras.\n",
    "- $y_i$: Rótulo verdadeiro da $i$-ésima amostra.\n",
    "- $\\hat{y}_i$: Probabilidade prevista para a $i$-ésima amostra.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Intuição:\n",
    "- A **BCELoss** penaliza o modelo mais severamente se a previsão estiver muito distante do valor real.\n",
    "- A perda é mínima quando a probabilidade prevista ($\\hat{y}$) está próxima de 1 para \\(y = 1\\) ou próxima de 0 para \\(y = 0\\).\n",
    "\n",
    "---\n",
    "\n",
    "#### Aplicação:\n",
    "- A **BCELoss** é amplamente utilizada em problemas de **classificação binária**:\n",
    "  - Exemplo: Detecção de fraude (fraude ou não), inadimplência (sim ou não).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "246a6584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Erro em Treino: 0.7288562655448914\n",
      "Epoch 2/100, Erro em Treino: 0.7156071662902832\n",
      "Epoch 3/100, Erro em Treino: 0.702572226524353\n",
      "Epoch 4/100, Erro em Treino: 0.6895853281021118\n",
      "Epoch 5/100, Erro em Treino: 0.6766160726547241\n",
      "Epoch 6/100, Erro em Treino: 0.6636762022972107\n",
      "Epoch 7/100, Erro em Treino: 0.6507443785667419\n",
      "Epoch 8/100, Erro em Treino: 0.6377660632133484\n",
      "Epoch 9/100, Erro em Treino: 0.6247169375419617\n",
      "Epoch 10/100, Erro em Treino: 0.6112528443336487\n",
      "Epoch 11/100, Erro em Treino: 0.5972772836685181\n",
      "Epoch 12/100, Erro em Treino: 0.5828590989112854\n",
      "Epoch 13/100, Erro em Treino: 0.5680578947067261\n",
      "Epoch 14/100, Erro em Treino: 0.5529263615608215\n",
      "Epoch 15/100, Erro em Treino: 0.5374132394790649\n",
      "Epoch 16/100, Erro em Treino: 0.5216258764266968\n",
      "Epoch 17/100, Erro em Treino: 0.5056553483009338\n",
      "Epoch 18/100, Erro em Treino: 0.4897063076496124\n",
      "Epoch 19/100, Erro em Treino: 0.47402632236480713\n",
      "Epoch 20/100, Erro em Treino: 0.45885682106018066\n",
      "Epoch 21/100, Erro em Treino: 0.44445598125457764\n",
      "Epoch 22/100, Erro em Treino: 0.4310356378555298\n",
      "Epoch 23/100, Erro em Treino: 0.4187715947628021\n",
      "Epoch 24/100, Erro em Treino: 0.40779566764831543\n",
      "Epoch 25/100, Erro em Treino: 0.39817988872528076\n",
      "Epoch 26/100, Erro em Treino: 0.3899291753768921\n",
      "Epoch 27/100, Erro em Treino: 0.3829793632030487\n",
      "Epoch 28/100, Erro em Treino: 0.37720054388046265\n",
      "Epoch 29/100, Erro em Treino: 0.3724261522293091\n",
      "Epoch 30/100, Erro em Treino: 0.3684442937374115\n",
      "Epoch 31/100, Erro em Treino: 0.36501774191856384\n",
      "Epoch 32/100, Erro em Treino: 0.361927330493927\n",
      "Epoch 33/100, Erro em Treino: 0.3589906394481659\n",
      "Epoch 34/100, Erro em Treino: 0.35604289174079895\n",
      "Epoch 35/100, Erro em Treino: 0.35297635197639465\n",
      "Epoch 36/100, Erro em Treino: 0.3497348725795746\n",
      "Epoch 37/100, Erro em Treino: 0.34630364179611206\n",
      "Epoch 38/100, Erro em Treino: 0.3427005708217621\n",
      "Epoch 39/100, Erro em Treino: 0.3389928936958313\n",
      "Epoch 40/100, Erro em Treino: 0.3352455794811249\n",
      "Epoch 41/100, Erro em Treino: 0.3315674662590027\n",
      "Epoch 42/100, Erro em Treino: 0.3280408978462219\n",
      "Epoch 43/100, Erro em Treino: 0.3247104585170746\n",
      "Epoch 44/100, Erro em Treino: 0.32163184881210327\n",
      "Epoch 45/100, Erro em Treino: 0.31883811950683594\n",
      "Epoch 46/100, Erro em Treino: 0.31632891297340393\n",
      "Epoch 47/100, Erro em Treino: 0.31407204270362854\n",
      "Epoch 48/100, Erro em Treino: 0.3120245635509491\n",
      "Epoch 49/100, Erro em Treino: 0.3101550042629242\n",
      "Epoch 50/100, Erro em Treino: 0.30841881036758423\n",
      "Epoch 51/100, Erro em Treino: 0.3068026900291443\n",
      "Epoch 52/100, Erro em Treino: 0.30528753995895386\n",
      "Epoch 53/100, Erro em Treino: 0.303841769695282\n",
      "Epoch 54/100, Erro em Treino: 0.30243852734565735\n",
      "Epoch 55/100, Erro em Treino: 0.3010718822479248\n",
      "Epoch 56/100, Erro em Treino: 0.29973745346069336\n",
      "Epoch 57/100, Erro em Treino: 0.2984330654144287\n",
      "Epoch 58/100, Erro em Treino: 0.29716756939888\n",
      "Epoch 59/100, Erro em Treino: 0.2959350645542145\n",
      "Epoch 60/100, Erro em Treino: 0.2947552502155304\n",
      "Epoch 61/100, Erro em Treino: 0.2936353087425232\n",
      "Epoch 62/100, Erro em Treino: 0.29259443283081055\n",
      "Epoch 63/100, Erro em Treino: 0.2916266918182373\n",
      "Epoch 64/100, Erro em Treino: 0.2907502353191376\n",
      "Epoch 65/100, Erro em Treino: 0.28995946049690247\n",
      "Epoch 66/100, Erro em Treino: 0.2892349064350128\n",
      "Epoch 67/100, Erro em Treino: 0.2885645627975464\n",
      "Epoch 68/100, Erro em Treino: 0.287937194108963\n",
      "Epoch 69/100, Erro em Treino: 0.2873331904411316\n",
      "Epoch 70/100, Erro em Treino: 0.28675055503845215\n",
      "Epoch 71/100, Erro em Treino: 0.2861848473548889\n",
      "Epoch 72/100, Erro em Treino: 0.2856367230415344\n",
      "Epoch 73/100, Erro em Treino: 0.28511515259742737\n",
      "Epoch 74/100, Erro em Treino: 0.2846084237098694\n",
      "Epoch 75/100, Erro em Treino: 0.2841125428676605\n",
      "Epoch 76/100, Erro em Treino: 0.28362032771110535\n",
      "Epoch 77/100, Erro em Treino: 0.2831299602985382\n",
      "Epoch 78/100, Erro em Treino: 0.2826468348503113\n",
      "Epoch 79/100, Erro em Treino: 0.2821761965751648\n",
      "Epoch 80/100, Erro em Treino: 0.2817116975784302\n",
      "Epoch 81/100, Erro em Treino: 0.2812443971633911\n",
      "Epoch 82/100, Erro em Treino: 0.28077927231788635\n",
      "Epoch 83/100, Erro em Treino: 0.2803030014038086\n",
      "Epoch 84/100, Erro em Treino: 0.27981895208358765\n",
      "Epoch 85/100, Erro em Treino: 0.27934521436691284\n",
      "Epoch 86/100, Erro em Treino: 0.2788800895214081\n",
      "Epoch 87/100, Erro em Treino: 0.2784207761287689\n",
      "Epoch 88/100, Erro em Treino: 0.2779700756072998\n",
      "Epoch 89/100, Erro em Treino: 0.2775220572948456\n",
      "Epoch 90/100, Erro em Treino: 0.2770802080631256\n",
      "Epoch 91/100, Erro em Treino: 0.2766476273536682\n",
      "Epoch 92/100, Erro em Treino: 0.27622315287590027\n",
      "Epoch 93/100, Erro em Treino: 0.2758083641529083\n",
      "Epoch 94/100, Erro em Treino: 0.275397926568985\n",
      "Epoch 95/100, Erro em Treino: 0.27498915791511536\n",
      "Epoch 96/100, Erro em Treino: 0.274584025144577\n",
      "Epoch 97/100, Erro em Treino: 0.2741854190826416\n",
      "Epoch 98/100, Erro em Treino: 0.27379998564720154\n",
      "Epoch 99/100, Erro em Treino: 0.2734249532222748\n",
      "Epoch 100/100, Erro em Treino: 0.2730523943901062\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo com dados de treino, 100 passadas ou epocas\n",
    "# A escolha de passadas depende da complexidade e da precisão do modelo\n",
    "epochs = 100\n",
    "\n",
    "# Inicia o loop de treinamento para o número especificado de épocas, pelo range de passadas (epochs)\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Zera os gradientes do otimizador para não acumular entre as épocas\n",
    "    # os gradientes são mantidos na memória a cada passada e zera em cada passada por causa da memoria\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Realiza a propagação para frente: calcula as previsões do modelo para os dados de treinamento\n",
    "    # realiza o back propagation no código de optimizer acima\n",
    "    # pega os outputs e grava em outputs\n",
    "    # executa o metodo forward \n",
    "    outputs = model(X_train)\n",
    "    \n",
    "    # Calcula a perda (erro) usando a função de perda especificada (criterion)\n",
    "    # pega os outputs e os valores reais de treino (y) e apresentam ao criterion, ela entrega o erro\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    # Realiza a propagação para trás: calcula os gradientes da perda em relação aos parâmetros do modelo\n",
    "    # Pega o erro e executa o backpropagation, que é o aprendizado do modelo propriamente dito.\n",
    "    loss.backward()\n",
    "    \n",
    "    # Atualiza os parâmetros do modelo usando o otimizador, para a próxima passagem.\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Imprime informações sobre a época atual e a perda\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Erro em Treino: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36a5597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinamento Concluído com Sucesso!\n",
      "\n",
      "Erro em Teste: 0.24647237360477448\n",
      "\n",
      "Modelos Salvos em Disco!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testar o modelo com dados de teste\n",
    "\n",
    "# Desativa o cálculo automático de gradientes para melhorar a eficiência durante a inferência\n",
    "# não precisa mais de gradiente, só precisa pra treinar, pra atualizar os pesos\n",
    "with torch.no_grad(): \n",
    "    \n",
    "    # Realiza a propagação para frente no conjunto de teste para obter as previsões do modelo\n",
    "    test_outputs = model(X_test)\n",
    "    \n",
    "    # Calcula a perda (erro) no conjunto de teste usando a função de perda (criterion)\n",
    "    # Pega as previsoes junto com o valor de y e passa pela fç de erro, pra calcular o erro em teste\n",
    "    # Já não executa a otimzação porque o modelo ja esta treinado.\n",
    "    test_loss = criterion(test_outputs, y_test)\n",
    "\n",
    "\n",
    "print('\\nTreinamento Concluído com Sucesso!\\n')\n",
    "\n",
    "print(f'Erro em Teste: {test_loss.item()}')\n",
    "\n",
    "print('\\nModelos Salvos em Disco!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecf1f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o scaler\n",
    "dump(scaler, 'modelos/michelle_scaler.pkl')\n",
    "\n",
    "# Salvar o modelo\n",
    "torch.save(model.state_dict(), 'modelos/michelle_modelo.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9da69",
   "metadata": {},
   "source": [
    "## Fim\n"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3ee21b6c",
   "metadata": {},
   "source": [
    "A principal diferença entre o que está sendo feito aqui (classificação binária com a função de erro Binary Cross Entropy Loss ou BCE) e uma regressão linear está no objetivo e na forma como o erro é calculado.\n",
    "\n",
    "Vamos detalhar essas diferenças:\n",
    "\n",
    "> 1. Objetivo do Problema\n",
    "\n",
    "**Classificação Binária (Usando BCE Loss):**\n",
    "O objetivo é prever a probabilidade de um evento ocorrer (como inadimplência: sim ou não).\n",
    "A saída é geralmente uma probabilidade entre 0 e 1, onde 1 indica a classe positiva e 0 indica a classe negativa.\n",
    "Aqui, usamos uma função de ativação sigmoide na última camada, que converte o valor final da rede neural para um valor entre 0 e 1.\n",
    "\n",
    "\n",
    "**Regressão Linear:**\n",
    "\n",
    "O objetivo é prever um valor contínuo (por exemplo, preço de uma casa).\n",
    "A saída não é uma probabilidade, mas sim um número real, que pode assumir qualquer valor contínuo.\n",
    "A regressão linear não usa a função sigmoide, pois a saída não precisa ser limitada ao intervalo de 0 a 1.\n",
    "\n",
    "\n",
    "> 2. Função de Erro:\n",
    "    \n",
    "Binary Cross Entropy Loss (BCE Loss):\n",
    "\n",
    "A BCE Loss mede o erro entre a previsão de probabilidade do modelo e o valor real (0 ou 1).\n",
    "\n",
    "A fórmula da **Binary Cross Entropy Loss** é:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Onde:\n",
    "-y é o valor verdadeiro (0 ou 1).\n",
    "- y^ é a previsão do modelo (probabilidade entre 0 e 1).\n",
    "\n",
    "Essa função é usada em problemas de classificação binária e penaliza o modelo com base em quão longe a \n",
    "previsão de probabilidade está do valor real.\n",
    "\n",
    "Essa fórmula penaliza fortemente previsões que estão longe da probabilidade correta, ou seja, quando o modelo está confiante na classe errada.\n",
    "É apropriada para problemas onde queremos que a saída seja uma probabilidade, pois a função de ativação sigmoide e a BCE Loss combinam bem para ajustar o modelo para esse fim.\n",
    "\n",
    "\n",
    "Erro Quadrático Médio (MSE) na Regressão Linear:\n",
    "\n",
    "A função de erro mais comum em regressão linear é o Mean Squared Error (MSE), que mede a média das diferenças quadradas entre as previsões e os valores reais.\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "Essa fórmula penaliza previsões que estão longe do valor verdadeiro ao quadrado, o que amplifica os erros maiores.\n",
    "O MSE é adequado para regressão porque mede o erro em valores contínuos e não se preocupa com probabilidades.\n",
    "\n",
    "> 3. Saída e Interpretação\n",
    "\n",
    "\n",
    "**Classificação Binária:**\n",
    "\n",
    "A saída é uma probabilidade (graças à função sigmoide), e o modelo faz a previsão final comparando essa probabilidade a um limiar (por exemplo, se a probabilidade é maior que 0.5, classifica como 1).\n",
    "\n",
    "\n",
    "**Regressão Linear:**\n",
    "\n",
    "A saída é um valor contínuo que o modelo tenta aproximar ao valor real. Não há função sigmoide ou outro tipo de ativação na última camada, pois não estamos tentando limitar o valor.\n",
    "\n",
    "\n",
    "#### Em Resumo\n",
    "\n",
    "> Para **classificação binária**, a função Binary Cross Entropy Loss (BCE) mede o erro em prever probabilidades e usa a função sigmoide para produzir uma saída entre 0 e 1.\n",
    "\n",
    "> Para **regressão linear**, a função Mean Squared Error (MSE) mede o erro em prever valores contínuos e não impõe limite à saída.\n",
    "A escolha da função de erro e da ativação final é crítica para alinhar o modelo ao objetivo específico, seja classificação ou regressão.\n",
    "\n",
    "Obs: overfitting o modelo aprende o padrão dos dados, aprender os ruidos, ao inves de aprender a generalização matemática,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacec9f9",
   "metadata": {},
   "source": [
    "Método é uma função dentro de uma classe, aqui nesse NB: class ModeloNN - metodo ModeloNN.\n",
    "\n",
    "Temos 2 métodos nessa função:\n",
    "\n",
    "1 - Método construtor __init__ , quando criar um objeto da class (instanciar a classe), tudo que está no construtor será executado para a iniciação do objeto model criado abaixo. Pra iniciar o objeto da classe.\n",
    "Essas camadas, vão aprendendo os padrões entre os dados\n",
    "\n",
    "2 - metodo foward - onde o modelo é efetivamente executado\n",
    "\n",
    "### Programação Orientada a Objetos:\n",
    "\n",
    "#### 1. Definindo a Classe `ModeloNN`\n",
    "\n",
    "- `class ModeloNN(nn.Module):`\n",
    "  - Criamos uma nova classe `ModeloNN` que herda de `nn.Module`. Isso é obrigatório para que a rede neural funcione dentro do PyTorch e possibilita o uso dos métodos e propriedades dessa classe base.\n",
    "\n",
    "#### 2. Método `__init__` (Construtor da Classe)\n",
    "\n",
    "- `def __init__(self, input_dim):`\n",
    "  - Esse é o **método construtor** da classe. Ele é chamado automaticamente quando você cria uma instância do `ModeloNN`.\n",
    "  - `input_dim` é o número de entradas (ou features) que o modelo vai receber, definido com base nos dados de entrada.\n",
    "  \n",
    "\n",
    "- `super(ModeloNN, self).__init__()`\n",
    "  - Aqui você chama o construtor da classe pai (`nn.Module`). Isso é necessário para inicializar as propriedades do `nn.Module` na sua classe, permitindo o uso de métodos internos do PyTorch.\n",
    "\n",
    "#### Definindo Camadas da Rede Neural\n",
    "\n",
    "- `self.fc1 = nn.Linear(input_dim, 128):`\n",
    "  - Define a primeira camada totalmente conectada (`fc1`). Recebe `input_dim` entradas e gera 128 saídas.\n",
    "\n",
    "\n",
    "- `self.fc2 = nn.Linear(128, 64):`\n",
    "  - Define a segunda camada, que recebe as 128 saídas da camada anterior e produz 64 saídas.\n",
    "\n",
    "\n",
    "- `self.fc3 = nn.Linear(64, 32):`\n",
    "  - Define a terceira camada, com 64 entradas e 32 saídas.\n",
    "\n",
    "\n",
    "- `self.fc4 = nn.Linear(32, 1):`\n",
    "  - Define a última camada com uma única saída (provavelmente para prever uma probabilidade de inadimplência).\n",
    "\n",
    "\n",
    "- `self.sigmoid = nn.Sigmoid()`\n",
    "  - A última camada utiliza a função de ativação **sigmoide** para restringir a saída entre 0 e 1, interpretável como uma probabilidade.\n",
    "\n",
    "#### 3. Método `forward` (Propagação para Frente)\n",
    "\n",
    "Esse método define como os dados passam pelas camadas da rede neural.\n",
    "\n",
    "- `x = torch.relu(self.fc1(x))`\n",
    "  - Passa a entrada `x` pela primeira camada (`fc1`) e aplica a função de ativação **ReLU**. \n",
    "  - A ReLU transforma valores negativos em zero, introduzindo não linearidade.\n",
    "  \n",
    "\n",
    "- `x = torch.relu(self.fc2(x))`\n",
    "  - Passa a saída da camada anterior (`fc2`) pela ReLU novamente.\n",
    "  \n",
    "\n",
    "- `x = torch.relu(self.fc3(x))`\n",
    "  - Aplica ReLU na terceira camada (`fc3`).\n",
    "  \n",
    "\n",
    "- `x = self.sigmoid(self.fc4(x))`\n",
    "  - Finalmente, passa pela última camada (`fc4`) e aplica a função de ativação sigmoide para gerar a saída entre 0 e 1.\n",
    "\n",
    "\n",
    "- `return x`\n",
    "  - Retorna a saída final da rede, que é uma probabilidade de inadimplência no intervalo de 0 a 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f783b91",
   "metadata": {},
   "source": [
    "### Comparação entre Gradiente Descendente e Adam\n",
    "\n",
    "\n",
    "### 1. **Gradiente Descendente Padrão**\n",
    "\n",
    "#### **Equação Geral**:\n",
    "A atualização dos pesos no Gradiente Descendente é dada por:\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\cdot \\nabla_\\theta J(\\theta_t)\n",
    "$$\n",
    "\n",
    "- $ \\theta_t $: Parâmetros atuais do modelo (pesos).\n",
    "- $ \\eta $: Taxa de aprendizado.\n",
    "- $ \\nabla_\\theta J(\\theta_t) $: Gradiente da função de perda $J$ em relação aos parâmetros $\\theta$.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Otimizador Adam (Adaptive Moment Estimation)**\n",
    "\n",
    "O **Adam** combina duas técnicas:\n",
    "- **Momentum** → Média móvel dos gradientes (suavização).\n",
    "- **RMSProp** → Adaptação da taxa de aprendizado individual para cada parâmetro.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Equações Matemáticas do Adam**\n",
    "\n",
    "1. **Cálculo do Gradiente**:\n",
    "   $$\n",
    "   g_t = \\nabla_\\theta J(\\theta_t)\n",
    "   $$\n",
    "\n",
    "2. **Cálculo do Momento de 1ª Ordem (Média dos Gradientes)**:\n",
    "   $$\n",
    "   m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot g_t\n",
    "   $$\n",
    "   - $ \\beta_1 $: Parâmetro de suavização (geralmente $0.9$).\n",
    "\n",
    "3. **Cálculo do Momento de 2ª Ordem (Variância dos Gradientes)**:\n",
    "   $$\n",
    "   v_t = \\beta_2 \\cdot v_{t-1} + (1 - \\beta_2) \\cdot g_t^2\n",
    "   $$\n",
    "   - $ \\beta_2 $: Parâmetro de suavização (geralmente $0.999$).\n",
    "\n",
    "4. **Correção de Viés**:\n",
    "   $$\n",
    "   \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
    "   $$\n",
    "\n",
    "5. **Atualização dos Pesos**:\n",
    "   $$\n",
    "   \\theta_{t+1} = \\theta_t - \\eta \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
    "   $$\n",
    "   - $ \\eta $: Taxa de aprendizado.\n",
    "   - $ \\sqrt{\\hat{v}_t} $: Ajuste da magnitude do gradiente.\n",
    "   - $ \\epsilon $: Termo pequeno (ex.: $10^{-8}$) para evitar divisão por zero.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Diferença Matemática**\n",
    "\n",
    "#### **Gradiente Descendente**:\n",
    "- Atualização simples usando apenas o gradiente atual:\n",
    "  $$\n",
    "  \\theta_{t+1} = \\theta_t - \\eta \\cdot g_t\n",
    "  $$\n",
    "\n",
    "#### **Adam**:\n",
    "- Taxa de aprendizado **adaptativa** com ajuste individual para cada parâmetro:\n",
    "  $$\n",
    "  \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Por que Adam é Mais Rápido e Eficiente?**\n",
    "\n",
    " - **Adaptação da Taxa de Aprendizado**:\n",
    "   - Parâmetros que variam muito recebem taxas menores.\n",
    "   - Parâmetros estáveis recebem taxas maiores.\n",
    "   \n",
    "\n",
    " - **Redução de Oscilações**:\n",
    "   - O **Momentum** suaviza a direção dos gradientes.\n",
    "   \n",
    "\n",
    " - **Correção de Viés**:\n",
    "   - Ajusta os momentos iniciais para evitar viés no início do treinamento.\n",
    "   \n",
    "\n",
    " - **Convergência Mais Rápida**:\n",
    "   - Combina o melhor do Momentum (aceleração) e RMSProp (adaptação).\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Conclusão**\n",
    "- O **Gradiente Descendente** usa uma **taxa fixa** de aprendizado para todos os parâmetros.\n",
    "- O **Adam** ajusta **automaticamente** a taxa de aprendizado para cada parâmetro com base no histórico dos gradientes.\n",
    "\n",
    "**Adam** é mais rápido e eficiente em problemas de otimização complexos, especialmente quando a superfície de perda possui **vales estreitos** (Regiões onde o gradiente muda rapidamente em uma direção e devagar em outra.) ou **direções oscilantes** (Gradientes inconsistentes que fazem o modelo \"pular\" de um lado para outro.).\n",
    "\n",
    "\n",
    "#### Visualização:\n",
    "\n",
    "> Gradiente Descendente: \"Desce a montanha com passos do mesmo tamanho.\"\n",
    "\n",
    "> Adam: \"Desce a montanha com passos ajustados para cada direção — passos menores onde a inclinação oscila muito e maiores onde há estabilidade.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7adfdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98dc212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
