{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d6f090e",
   "metadata": {},
   "source": [
    "### <font color='darkred'>IA Aplicado a Finanças</font>\n",
    "### <font color='darkgreen'>Auditoria Contábil </font>\n",
    "### <font color='darkblue'> Aprendizado de Máquina não Supervisionado DBSCAN</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbbc25e",
   "metadata": {},
   "source": [
    "**O DBSCAN (Density-Based Spatial Clustering of Applications with Noise) é um algoritmo popular de clustering baseado em densidade.**\n",
    "\n",
    "- Em vez de usar a noção tradicional de centróides (como no k-means) para identificar clusters,o DBSCAN identifica regiões densas de pontos de dados no espaço. Essas regiões são separadas por regiões de baixa densidade.\n",
    "\n",
    "\n",
    "- **Aqui está uma descrição passo a passo de como o DBSCAN funciona:**\n",
    "\n",
    "> **1- Parâmetros Iniciais:**\n",
    "\n",
    "- **O algoritmo necessita de dois parâmetros:eps (epsilon) e minPts.**\n",
    "- eps: Define o raio de uma vizinhança.\n",
    "- minPts: Número mínimo de pontos necessários para formar uma região densa.\n",
    "\n",
    "\n",
    "> **2- Processo de Clustering:** \n",
    "\n",
    " **Para cada ponto do conjunto de dados:**\n",
    "\n",
    "- Se o ponto já foi visitado, vá para o próximo ponto.\n",
    "- Se não, marque o ponto como visitado.\n",
    "- Consulte a vizinhança do ponto dentro do raio eps.\n",
    "- Se há menos pontos na vizinhança do que minPts, marque esse ponto como ruído (ou ponto de borda).\n",
    "- Caso contrário, inicie um novo cluster e adicione todos os pontos densamente conectados a esse ponto ao cluster.\n",
    "\n",
    "> **3- Expansão do Cluster:**\n",
    "\n",
    "**Para cada ponto novo no cluster:**\n",
    "\n",
    "- Consulte os pontos dentro de sua vizinhança.\n",
    "- Se um ponto da vizinhança ainda não foi visitado, marque-o como visitado e repita o processo para ele.\n",
    "- Se o ponto tem uma quantidade suficiente de pontos em sua vizinhança, expanda o cluster para incluí-lo.\n",
    "\n",
    "> **4- Finalização:**\n",
    "\n",
    "O processo termina quando todos os pontos foram visitados. No final, todos os pontos estarão ou em um cluster específico ou marcados como ruído.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac041e6",
   "metadata": {},
   "source": [
    "> **Características do DBSCAN:**\n",
    "\n",
    "- **Vantagens:**\n",
    "\n",
    "- Pode  encontrar  clusters  de  formas  arbitrárias,  ao  contrário  do  k-means,  que assume que os clusters são convexos e isotrópicos.\n",
    "- Não requer que o número de clusters seja especificado antecipadamente.\n",
    "- É robusto a pontos de ruído.\n",
    "\n",
    "\n",
    "- **Desvantagens:**\n",
    "\n",
    "- Não se sai bem quando os clusters têm variações significativas de densidade.\n",
    "- A  escolha  dos  parâmetros  eps  e  minPts  pode  ser  desafiadora  e  pode  exigir experimentação.\n",
    "\n",
    "ODBSCAN é uma técnica poderosa, especialmente quando os conjuntos de dados têm clusters  de  formas  complexas  e  não  uniformes e  quando  a  presença  de  ruído  é  uma preocupação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5529c82c",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html\n",
    "\n",
    "https://optuna.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c9a2a1",
   "metadata": {},
   "source": [
    "### <font color='darkred'>Carregando e Instalando Pacotes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b18b96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d124967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
      "     -------------------------------------- 362.8/362.8 kB 3.8 MB/s eta 0:00:00\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
      "     -------------------------------------- 233.2/233.2 kB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: tqdm in c:\\users\\miche\\anaconda3\\lib\\site-packages (from optuna) (4.64.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\miche\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\miche\\anaconda3\\lib\\site-packages (from optuna) (1.23.5)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.3.0)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.6/78.6 kB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\miche\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
      "Installing collected packages: Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.6 alembic-1.13.3 colorlog-6.9.0 optuna-4.0.0\n"
     ]
    }
   ],
   "source": [
    "# pacote python para otimização de hiperparâmetros\n",
    "#!pip install optuna  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c18978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import optuna #otimização dos hiperparametros\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN #pacote cluster e dentro o pacote DBSCAN\n",
    "\n",
    "#pacote preprocessing e dentro a função StandardScaler\n",
    "# Que permite criar um padronizador dos dados, importante no trabalho com tecnicas de clusterização.\n",
    "# Clusterização - devemos deixar os dados na mesma escala!\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# medida de avaliação de algoritmo de clusterização\n",
    "# Como não temos valores de saídas nos dados, não temos como usar metricas de aprendizado supervisionado como acurácia, precisão \n",
    "from sklearn.metrics import silhouette_score \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dde0bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Michelle Bouhid\n",
      "\n",
      "optuna  : 4.0.0\n",
      "platform: 1.0.8\n",
      "pandas  : 1.5.3\n",
      "sklearn : 1.3.0\n",
      "numpy   : 1.23.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Michelle Bouhid\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3879521",
   "metadata": {},
   "source": [
    "### <font color='darkred'>Carregando Dados</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c3dbb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados\n",
    "df = pd.read_csv('transacoes_contabeis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bfd033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a data da transação para uma representação numérica - \n",
    "# Não vamos isar data como data, vamos usar como categoria.\n",
    "# Nesse projeto não estamos trabalhando com séries temporais, não precisamos colocar data como indice\n",
    "# Queremos agrupar os dados por similaridade, não precisamos de ordem cronologica como série temporais\n",
    "# Como a data tem traço - computador interpreta como variável categorica, texto que não pode ser usado nesse caso.  \n",
    "# Temos mtas datas repetidas se comportando como categoria.\n",
    "# Converte em datetime e depois converte pra inteiro no formato do Numpy pq não pode usar como texto.\n",
    "\n",
    "df['Data_Transacao'] = pd.to_datetime(df['Data_Transacao']).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b31860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona as colunas que vamos usar para identificar possíveis atividades de smurfing\n",
    "# Salva as colunas na variavel atributos e chama de X o df [atributos]\n",
    "atributos = ['ID_Conta', 'Data_Transacao', 'Valor']\n",
    "X = df[atributos]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16172f94",
   "metadata": {},
   "source": [
    "**Por que Normalizamos Atributos?**\n",
    "\n",
    "A normalização dos atributos é uma etapa crucial em muitas técnicas de análise de dados, incluindo a clusterização. No contexto do algoritmo DBSCAN (Density-Based Spatial Clustering of Applications  with  Noise)  e  de  muitos  outros  algoritmos  de  aprendizado  de  máquina,  a normalização é especialmente importante por diversas razões:\n",
    "\n",
    "- **Escala dos Atributos:** DBSCAN funciona com base na noção de densidade e distância. Se os atributos não estiverem na mesma escala, um atributo com uma variação maior dominará os resultados, tornando a medida de distância efetivamente baseada nesse atributo.\n",
    "\n",
    "\n",
    "- **Sensibilidade à Distância:** O DBSCAN classifica os pontos como centrais, de fronteira ou de ruído com base na densidade em um raio especificado (eps). Se os atributos não estiverem normalizados, este raio pode não ser representativo para todos os atributos, levando a clusters distorcidos.\n",
    "\n",
    "\n",
    "- **Melhor Interpretação:** Ao trabalhar com dados em escalas diferentes, pode ser difícil visualizar e interpretar os clusters. A normalização ajuda a colocar todos os atributos em uma escala similar, tornando mais fácil a visualização e interpretação dos clusters.\n",
    "\n",
    "\n",
    "- **Desempenho do Algoritmo:** Alguns algoritmos podem convergir mais rápido quando os dados são normalizados, pois oproblema se torna mais \"uniforme\". No caso do DBSCAN, a normalização pode resultar em uma melhor identificação dos clusters e pontos de ruído.\n",
    "\n",
    "\n",
    "- **Uniformidade  em Diferentes Domínios:**  Ao  lidar  com  atributos  que  representam diferentes  domínios  (por  exemplo,  peso  em  quilogramas  e  altura  em  centímetros),  a normalização garante que cada domínio contribua de maneira equitativa para a análise.\n",
    "\n",
    "\n",
    "- **Prevenção de Distorções:** Sem normalização, clusters podem ser formados com base apenas nas magnitudes dos atributos, em vez de suas relações, o que pode não ser desejado em muitos cenários.\n",
    "\n",
    "É importante mencionar que, embora a normalização seja benéfica em muitos cenários, nem sempre é apropriada. Em alguns contextos, as escalas originais dos atributos são cruciais para a análise e a normalização pode obscurecer padrões importantes. Portanto, sempre é crucial entender o problema e os dados com os quais você está trabalhando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dcd4b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar os recursos para que eles tenham uma média de 0 e um desvio padrão de 1\n",
    "# Cada algoritmo tem premissas e suposições, o DBSCAN precisa que os dados estejam na mesma escala.\n",
    "# cria o objeto scaler, que é uma instancia da classe StandardScaler\n",
    "# O objeto scaler, tem metodos e atributos, vamos chamar o \"fit\"\n",
    "# fit faz o treinamento do X e transforma o X.\n",
    "# Aplicando um truque matematico que modifica os dados mas não modifica a informação\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e1960d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a função de otimização que será utilizada pelo optuna\n",
    "def optimize(trial):\n",
    "\n",
    "    # Define um valor para 'eps' no intervalo de 0.1 a 1.0 usando o objeto `trial`\n",
    "    # Podemos otimizar mais parametros se tiver tempo, em aula so otimizamos eps e min samples\n",
    "    # usamos valores um pouco abaixo e acima do valor padrão sugerido na documentação\n",
    "    # suggest_float pq o eps é float\n",
    "    eps = trial.suggest_float('eps', 0.1, 1.0)\n",
    "\n",
    "    # Define um valor inteiro para 'min_samples' no intervalo de 2 a 10 usando o objeto `trial`\n",
    "    # suggest_int pq o min_samples é inteiro\n",
    "    min_samples = trial.suggest_int('min_samples', 2, 10)\n",
    "\n",
    "    # Instancia o algoritmo DBSCAN com os parâmetros sugeridos anteriormente\n",
    "    # chama o modelo DBSCAN e passa os hiperparametros trabalhados acima\n",
    "    dbscan = DBSCAN(eps = eps, min_samples = min_samples)\n",
    "\n",
    "    # Aplica o algoritmo DBSCAN no conjunto de dados X e retorna as etiquetas para cada ponto de dado\n",
    "    # Labels = clusters \n",
    "    labels = dbscan.fit_predict(X)\n",
    "    \n",
    "    # Usamos o coeficiente silhouette para avaliar a qualidade dos clusters. \n",
    "    # O coeficiente silhouette varia de -1 a 1. \n",
    "    # Valores Próximos de 1: Indicam que os pontos são muito semelhantes aos outros pontos do cluster e diferentes dos pontos de outros clusters.\n",
    "    # Valores Próximos de 0: Indicam que os pontos estão próximos da fronteira de decisão entre dois clusters.\n",
    "    # Valores Próximos de -1: Indicam que os pontos foram atribuídos ao cluster errado. (anomalia!)    \n",
    "    # Como o coeficiente silhouette é indefinido para um único cluster, verificamos se temos mais de um cluster antes de calcular.\n",
    "    # Só faz sentido calcular o coeficientes se tiver mais de 1 clusters para comparação\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0) #verifica o numero de cluster\n",
    "    if n_clusters > 1: #calcula se for maior que 1 cluster\n",
    "        score = silhouette_score(X, labels)\n",
    "    else:\n",
    "        score = -1 # se não for maior que 1 já caracteriza em -1 (modelo ruim)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd7094cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-02 09:29:36,714] A new study created in memory with name: no-name-97c6898f-494c-4cfd-97ea-0909a6e2e762\n",
      "[I 2024-11-02 09:29:36,798] Trial 0 finished with value: 0.1689376235248055 and parameters: {'eps': 0.11679733787122164, 'min_samples': 5}. Best is trial 0 with value: 0.1689376235248055.\n",
      "[I 2024-11-02 09:29:36,819] Trial 1 finished with value: -1.0 and parameters: {'eps': 0.9444631491604687, 'min_samples': 7}. Best is trial 0 with value: 0.1689376235248055.\n",
      "[I 2024-11-02 09:29:36,879] Trial 2 finished with value: 0.2541009050992981 and parameters: {'eps': 0.25343319191156033, 'min_samples': 3}. Best is trial 2 with value: 0.2541009050992981.\n",
      "[I 2024-11-02 09:29:36,931] Trial 3 finished with value: 0.12842818750789525 and parameters: {'eps': 0.17647049212324384, 'min_samples': 3}. Best is trial 2 with value: 0.2541009050992981.\n",
      "[I 2024-11-02 09:29:36,945] Trial 4 finished with value: -1.0 and parameters: {'eps': 0.4876865969964763, 'min_samples': 4}. Best is trial 2 with value: 0.2541009050992981.\n",
      "[I 2024-11-02 09:29:36,962] Trial 5 finished with value: -1.0 and parameters: {'eps': 0.4487518708056998, 'min_samples': 6}. Best is trial 2 with value: 0.2541009050992981.\n",
      "[I 2024-11-02 09:29:36,982] Trial 6 finished with value: -1.0 and parameters: {'eps': 0.7294687726664035, 'min_samples': 4}. Best is trial 2 with value: 0.2541009050992981.\n",
      "[I 2024-11-02 09:29:37,000] Trial 7 finished with value: -1.0 and parameters: {'eps': 0.5848373988997752, 'min_samples': 3}. Best is trial 2 with value: 0.2541009050992981.\n",
      "[I 2024-11-02 09:29:37,015] Trial 8 finished with value: -1.0 and parameters: {'eps': 0.49749216627116544, 'min_samples': 8}. Best is trial 2 with value: 0.2541009050992981.\n",
      "[I 2024-11-02 09:29:37,066] Trial 9 finished with value: 0.04833917222205861 and parameters: {'eps': 0.31998683144330714, 'min_samples': 8}. Best is trial 2 with value: 0.2541009050992981.\n",
      "[I 2024-11-02 09:29:37,129] Trial 10 finished with value: 0.09233332627733314 and parameters: {'eps': 0.28300274571327, 'min_samples': 10}. Best is trial 2 with value: 0.2541009050992981.\n",
      "[I 2024-11-02 09:29:37,186] Trial 11 finished with value: 0.1689376235248055 and parameters: {'eps': 0.12089012607672814, 'min_samples': 5}. Best is trial 2 with value: 0.2541009050992981.\n",
      "[I 2024-11-02 09:29:37,240] Trial 12 finished with value: 0.1885629967017667 and parameters: {'eps': 0.2867835505857711, 'min_samples': 2}. Best is trial 2 with value: 0.2541009050992981.\n",
      "[I 2024-11-02 09:29:37,307] Trial 13 finished with value: -0.293241438979436 and parameters: {'eps': 0.31597055299698923, 'min_samples': 2}. Best is trial 2 with value: 0.2541009050992981.\n",
      "[I 2024-11-02 09:29:37,365] Trial 14 finished with value: 0.31232303523831356 and parameters: {'eps': 0.2643498519736225, 'min_samples': 2}. Best is trial 14 with value: 0.31232303523831356.\n",
      "[I 2024-11-02 09:29:37,396] Trial 15 finished with value: -1.0 and parameters: {'eps': 0.6611244819763942, 'min_samples': 2}. Best is trial 14 with value: 0.31232303523831356.\n",
      "[I 2024-11-02 09:29:37,459] Trial 16 finished with value: 0.028495935105544733 and parameters: {'eps': 0.3937753432750913, 'min_samples': 3}. Best is trial 14 with value: 0.31232303523831356.\n",
      "[I 2024-11-02 09:29:37,519] Trial 17 finished with value: 0.15088540594602942 and parameters: {'eps': 0.22492682587837048, 'min_samples': 4}. Best is trial 14 with value: 0.31232303523831356.\n",
      "[I 2024-11-02 09:29:37,549] Trial 18 finished with value: -1.0 and parameters: {'eps': 0.9117093918195365, 'min_samples': 5}. Best is trial 14 with value: 0.31232303523831356.\n",
      "[I 2024-11-02 09:29:37,613] Trial 19 finished with value: -0.3202491672701811 and parameters: {'eps': 0.3889406658308561, 'min_samples': 2}. Best is trial 14 with value: 0.31232303523831356.\n",
      "[I 2024-11-02 09:29:37,639] Trial 20 finished with value: -1.0 and parameters: {'eps': 0.7806656049836651, 'min_samples': 10}. Best is trial 14 with value: 0.31232303523831356.\n",
      "[I 2024-11-02 09:29:37,701] Trial 21 finished with value: 0.31541531673214523 and parameters: {'eps': 0.2028754062523066, 'min_samples': 2}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:37,765] Trial 22 finished with value: 0.1895165337953879 and parameters: {'eps': 0.2020770906114224, 'min_samples': 3}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:37,831] Trial 23 finished with value: -0.3332665957722712 and parameters: {'eps': 0.3820106838250189, 'min_samples': 2}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:37,893] Trial 24 finished with value: 0.24095024268105425 and parameters: {'eps': 0.2191242476869577, 'min_samples': 3}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:37,922] Trial 25 finished with value: -1.0 and parameters: {'eps': 0.5755687941398345, 'min_samples': 4}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:37,980] Trial 26 finished with value: 0.07992819646614464 and parameters: {'eps': 0.10639159473960857, 'min_samples': 2}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,039] Trial 27 finished with value: 0.25475287009681935 and parameters: {'eps': 0.2537806080632105, 'min_samples': 3}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,101] Trial 28 finished with value: 0.07648839644334186 and parameters: {'eps': 0.1714455678362402, 'min_samples': 4}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,163] Trial 29 finished with value: -0.25986447814217994 and parameters: {'eps': 0.3614648425745503, 'min_samples': 6}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,229] Trial 30 finished with value: 0.16962461839737544 and parameters: {'eps': 0.131289375061565, 'min_samples': 5}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,295] Trial 31 finished with value: 0.25834076500934006 and parameters: {'eps': 0.2554541354107953, 'min_samples': 3}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,361] Trial 32 finished with value: -0.39458178745120426 and parameters: {'eps': 0.3404529190314649, 'min_samples': 3}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,415] Trial 33 finished with value: 0.3124408868335751 and parameters: {'eps': 0.2637381603192965, 'min_samples': 2}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,481] Trial 34 finished with value: 0.234809149322408 and parameters: {'eps': 0.16888775173922504, 'min_samples': 2}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,545] Trial 35 finished with value: -0.07206624832009298 and parameters: {'eps': 0.43557632921689315, 'min_samples': 2}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,605] Trial 36 finished with value: 0.2603253328068681 and parameters: {'eps': 0.2517612866974265, 'min_samples': 3}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,669] Trial 37 finished with value: 0.2427221959929493 and parameters: {'eps': 0.174425556836099, 'min_samples': 2}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,691] Trial 38 finished with value: -1.0 and parameters: {'eps': 0.4901891960500884, 'min_samples': 4}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,713] Trial 39 finished with value: -1.0 and parameters: {'eps': 0.42772175212996266, 'min_samples': 3}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,773] Trial 40 finished with value: 0.07239643906932168 and parameters: {'eps': 0.29530131101825535, 'min_samples': 8}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,835] Trial 41 finished with value: 0.27722104487421667 and parameters: {'eps': 0.24634322685009713, 'min_samples': 3}. Best is trial 21 with value: 0.31541531673214523.\n",
      "[I 2024-11-02 09:29:38,895] Trial 42 finished with value: 0.3469100427946081 and parameters: {'eps': 0.24397910521711808, 'min_samples': 2}. Best is trial 42 with value: 0.3469100427946081.\n",
      "[I 2024-11-02 09:29:38,951] Trial 43 finished with value: 0.15354303503382802 and parameters: {'eps': 0.14039366622371643, 'min_samples': 2}. Best is trial 42 with value: 0.3469100427946081.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-02 09:29:39,007] Trial 44 finished with value: 0.16864360504156217 and parameters: {'eps': 0.20360348751804835, 'min_samples': 7}. Best is trial 42 with value: 0.3469100427946081.\n",
      "[I 2024-11-02 09:29:39,076] Trial 45 finished with value: -0.46213138013499094 and parameters: {'eps': 0.33411473028593547, 'min_samples': 2}. Best is trial 42 with value: 0.3469100427946081.\n",
      "[I 2024-11-02 09:29:39,140] Trial 46 finished with value: 0.31734427174890295 and parameters: {'eps': 0.26824127548847465, 'min_samples': 2}. Best is trial 42 with value: 0.3469100427946081.\n",
      "[I 2024-11-02 09:29:39,209] Trial 47 finished with value: 0.1277692590517116 and parameters: {'eps': 0.29237642789993595, 'min_samples': 2}. Best is trial 42 with value: 0.3469100427946081.\n",
      "[I 2024-11-02 09:29:39,251] Trial 48 finished with value: -1.0 and parameters: {'eps': 0.9967812208690905, 'min_samples': 9}. Best is trial 42 with value: 0.3469100427946081.\n",
      "[I 2024-11-02 09:29:39,278] Trial 49 finished with value: -1.0 and parameters: {'eps': 0.6433318465928849, 'min_samples': 4}. Best is trial 42 with value: 0.3469100427946081.\n",
      "[I 2024-11-02 09:29:39,301] Trial 50 finished with value: -1.0 and parameters: {'eps': 0.5144853324177429, 'min_samples': 2}. Best is trial 42 with value: 0.3469100427946081.\n",
      "[I 2024-11-02 09:29:39,363] Trial 51 finished with value: 0.2680259370473483 and parameters: {'eps': 0.2577953660101671, 'min_samples': 3}. Best is trial 42 with value: 0.3469100427946081.\n",
      "[I 2024-11-02 09:29:39,428] Trial 52 finished with value: 0.3615356203010035 and parameters: {'eps': 0.22700178314823846, 'min_samples': 2}. Best is trial 52 with value: 0.3615356203010035.\n",
      "[I 2024-11-02 09:29:39,487] Trial 53 finished with value: 0.31178199024785286 and parameters: {'eps': 0.20082388236932952, 'min_samples': 2}. Best is trial 52 with value: 0.3615356203010035.\n",
      "[I 2024-11-02 09:29:39,550] Trial 54 finished with value: -0.293241438979436 and parameters: {'eps': 0.31499014702813155, 'min_samples': 2}. Best is trial 52 with value: 0.3615356203010035.\n",
      "[I 2024-11-02 09:29:39,613] Trial 55 finished with value: 0.19584271919385923 and parameters: {'eps': 0.28572914104702496, 'min_samples': 2}. Best is trial 52 with value: 0.3615356203010035.\n",
      "[I 2024-11-02 09:29:39,677] Trial 56 finished with value: 0.0945899741667334 and parameters: {'eps': 0.15309175667826924, 'min_samples': 3}. Best is trial 52 with value: 0.3615356203010035.\n",
      "[I 2024-11-02 09:29:39,744] Trial 57 finished with value: 0.24624143328544776 and parameters: {'eps': 0.2205431343478005, 'min_samples': 3}. Best is trial 52 with value: 0.3615356203010035.\n",
      "[I 2024-11-02 09:29:39,813] Trial 58 finished with value: -0.4608428170245561 and parameters: {'eps': 0.36124646567970115, 'min_samples': 2}. Best is trial 52 with value: 0.3615356203010035.\n",
      "[I 2024-11-02 09:29:39,838] Trial 59 finished with value: -1.0 and parameters: {'eps': 0.824282399929201, 'min_samples': 4}. Best is trial 52 with value: 0.3615356203010035.\n",
      "[I 2024-11-02 09:29:39,905] Trial 60 finished with value: 0.28369860526627705 and parameters: {'eps': 0.18725945413574824, 'min_samples': 2}. Best is trial 52 with value: 0.3615356203010035.\n",
      "[I 2024-11-02 09:29:39,968] Trial 61 finished with value: 0.36172766840283227 and parameters: {'eps': 0.22618912879587735, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,025] Trial 62 finished with value: 0.2651900266366526 and parameters: {'eps': 0.27246005148517516, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,089] Trial 63 finished with value: 0.07857854234847891 and parameters: {'eps': 0.10381461978128419, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,146] Trial 64 finished with value: 0.26513851500489244 and parameters: {'eps': 0.23033163563319814, 'min_samples': 3}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,214] Trial 65 finished with value: -0.2161150573885047 and parameters: {'eps': 0.3100661755975094, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,273] Trial 66 finished with value: -0.26235292009051586 and parameters: {'eps': 0.3555890783636882, 'min_samples': 6}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,335] Trial 67 finished with value: 0.07377133468082361 and parameters: {'eps': 0.14586989067373224, 'min_samples': 3}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,399] Trial 68 finished with value: -0.08912101241348473 and parameters: {'eps': 0.4027220607874781, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,459] Trial 69 finished with value: 0.3587878732588561 and parameters: {'eps': 0.23215267365191228, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,514] Trial 70 finished with value: 0.12842818750789525 and parameters: {'eps': 0.17666637860783826, 'min_samples': 3}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,580] Trial 71 finished with value: 0.3549171398211092 and parameters: {'eps': 0.22917692959465477, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,642] Trial 72 finished with value: 0.35169204115071667 and parameters: {'eps': 0.22857398297262485, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,704] Trial 73 finished with value: 0.3374302488355076 and parameters: {'eps': 0.2131732071328405, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,763] Trial 74 finished with value: 0.3585998719767586 and parameters: {'eps': 0.23336567331391148, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,815] Trial 75 finished with value: 0.34544051361369243 and parameters: {'eps': 0.21691114745996967, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,876] Trial 76 finished with value: 0.27413827884321 and parameters: {'eps': 0.23560162279128438, 'min_samples': 3}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:40,942] Trial 77 finished with value: 0.20646632103378543 and parameters: {'eps': 0.15797648974582967, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,002] Trial 78 finished with value: 0.0890626370525926 and parameters: {'eps': 0.12278243278159744, 'min_samples': 3}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,059] Trial 79 finished with value: 0.2842167103030987 and parameters: {'eps': 0.18747020294563088, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,118] Trial 80 finished with value: 0.2590185316753772 and parameters: {'eps': 0.22769445221828838, 'min_samples': 3}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,176] Trial 81 finished with value: 0.3374302488355076 and parameters: {'eps': 0.21315784452423878, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,255] Trial 82 finished with value: -0.001985236556797246 and parameters: {'eps': 0.29886176371606443, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,315] Trial 83 finished with value: 0.34966737127449093 and parameters: {'eps': 0.24045182498960013, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,392] Trial 84 finished with value: -0.4357491541732247 and parameters: {'eps': 0.3290311580680803, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,445] Trial 85 finished with value: 0.2857270382204125 and parameters: {'eps': 0.18875121750024745, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,507] Trial 86 finished with value: 0.3497850564819524 and parameters: {'eps': 0.2398087488373464, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,568] Trial 87 finished with value: 0.27722104487421667 and parameters: {'eps': 0.24629761525603042, 'min_samples': 3}. Best is trial 61 with value: 0.36172766840283227.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-02 09:29:41,635] Trial 88 finished with value: 0.1897904338563815 and parameters: {'eps': 0.28642523395910197, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,698] Trial 89 finished with value: 0.26520258771430916 and parameters: {'eps': 0.26405180545706924, 'min_samples': 3}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,759] Trial 90 finished with value: 0.16415002608649573 and parameters: {'eps': 0.135761197423663, 'min_samples': 7}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,822] Trial 91 finished with value: 0.35793526188362884 and parameters: {'eps': 0.23307740543790753, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,885] Trial 92 finished with value: 0.34889604377079503 and parameters: {'eps': 0.24550496278341757, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:41,955] Trial 93 finished with value: 0.2205799218282131 and parameters: {'eps': 0.1631698306970822, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:42,020] Trial 94 finished with value: 0.345982611839211 and parameters: {'eps': 0.2367768721317683, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:42,082] Trial 95 finished with value: 0.2591051096039317 and parameters: {'eps': 0.2731281673503847, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:42,145] Trial 96 finished with value: 0.29184273493576757 and parameters: {'eps': 0.19453910194532334, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:42,211] Trial 97 finished with value: -0.29072383834454785 and parameters: {'eps': 0.31734471370807105, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:42,277] Trial 98 finished with value: -0.40670146363987025 and parameters: {'eps': 0.34655824215675257, 'min_samples': 3}. Best is trial 61 with value: 0.36172766840283227.\n",
      "[I 2024-11-02 09:29:42,335] Trial 99 finished with value: -0.1817802310492133 and parameters: {'eps': 0.30545824193907084, 'min_samples': 2}. Best is trial 61 with value: 0.36172766840283227.\n"
     ]
    }
   ],
   "source": [
    "# Otimizando os hiperparâmetros\n",
    "# Cria o objeto study na direção maximize\n",
    "# A partir do objeto study chama a função optimize e dentro dessa função chama a função criada acima\n",
    "# Que tb se chama optimize!! (didaticamente pra chamar atenção, pode ser qq função :)\n",
    "# vai fazer o estudo por 100 tentativas\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(optimize, n_trials = 100) #pode colocar mais trials se quiser mais combinações de otimização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d62760",
   "metadata": {},
   "source": [
    "### Coeficiente de Avaliação da Performance do Modelo\n",
    "\n",
    "O  coeficiente  silhouette  é  uma  métrica  usada  para  calcular  a eficiênciade  um agrupamento, ou seja, o quão bem cada objeto está agrupado com outros objetos em um cluster. Ele pode ser aplicado a vários algoritmos de clusterização, incluindo o DBSCAN.\n",
    "\n",
    "Para um único ponto de dados, o coeficiente silhouette é calculado da seguinte maneira:\n",
    "\n",
    "- a: É a distância média do ponto para os outros pontos no mesmo cluster. Quanto menor for este valor, melhor.\n",
    "\n",
    "- b: É a menor distância média do ponto para os pontos em um cluster diferente, do  qual  o  ponto  não  faz  parte.  Idealmente,  este  valor  será  grande  se  o agrupamento for bom.\n",
    "\n",
    "Para obter o coeficiente silhouette para todo o conjunto de dados, calcula-se a média do silhouette de todos os pontos.\n",
    "\n",
    "A  métrica  silhouette_score  no  contexto  do  DBSCAN  (ou  qualquer  algoritmo  de clusterização) fornece insights valiosos:\n",
    "\n",
    "- Valores Próximos de 1: Indicam que os pontos são muito semelhantes aos outros pontos do cluster e diferentes dos pontos de outros clusters.\n",
    "\n",
    "- Valores Próximos de 0: Indicam que os pontos estão próximos da fronteira de decisão entre dois clusters.\n",
    "\n",
    "- Valores Próximos de -1: Indicam que os pontos foram atribuídos ao cluster errado.\n",
    "\n",
    "A  avaliação  com  o  coeficiente  silhouette  pode  ser  particularmente  útil  ao  ajustar hiperparâmetros do DBSCAN (como eps e min_samples) porque fornece uma métrica objetiva para a qualidade dos clusters. No entanto, é importante considerar que, para o DBSCAN, pode haver pontos considerados \"ruído\" que não pertencem a nenhum cluster. Esses pontos não são diretamente considerados no cálculo do coeficiente silhouette.\n",
    "\n",
    "Assim, é válido observar que, enquanto o coeficiente silhouette fornece uma métrica objetiva, a melhor configuração para um algoritmo de clusterização pode também depender do contexto e do objetivo específico da análise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37a8c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter os melhores hiperparâmetros\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abbf8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o DBSCAN com os melhores hiperparâmetros\n",
    "dbscan = DBSCAN(eps = best_params['eps'], min_samples = best_params['min_samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b8268eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina o DBSCAN com os melhores hiperparâmetros\n",
    "# Cria a coluna Cluster no nosso df\n",
    "df['Cluster'] = dbscan.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a918b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontraremos agora os clusters que têm um número de transações acima de um determinado limiar.\n",
    "# Nesse caso, estamos usando um limiar de 5, mas você pode ajustá-lo conforme necessário.\n",
    "# Regra de auditoria, encontrar cluster com mais de 5 elementos de dados - pouco restritiva\n",
    "# escolha menos restritiva pra passar pro especialista em contabilidade fazer o filtro tecnico.\n",
    "# Pela a coluna cluster e faz uma contagem, com base nessa contagem palica um filtro > limiar e busca o indice dela\n",
    "limiar = 5\n",
    "clusters_suspeitos = df['Cluster'].value_counts()[df['Cluster'].value_counts() > limiar].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "716b8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo as transações nos clusters suspeitos\n",
    "# filtro, a coluna CLuster esta dentro desse objeto \"cluster suspeitos\"\n",
    "transacoes_suspeitas = df[df['Cluster'].isin(clusters_suspeitos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37cf33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando o dataframe com base no valor da coluna 'Cluster'\n",
    "# Filtro pela regra do DBSCAN, (-1 == anomalia)\n",
    "filtrado = transacoes_suspeitas[transacoes_suspeitas['Cluster'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bdf2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Na implementação DBSCAN do scikit-learn, o rótulo de cluster -1 significa que a amostra foi considerada como ruído.\n",
    "\n",
    "# O DBSCAN, que significa \"Density-Based Spatial Clustering of Applications with Noise\", é um algoritmo de agrupamento que cria clusters de \n",
    "# regiões de alta densidade no espaço de recursos e identifica amostras individuais que estão em áreas de baixa densidade como ruído.\n",
    "\n",
    "# Divide os dados em grupos, com base em distancia matemática, se algum dado não couber em nenhum grupo, identifica como anomalia.\n",
    "\n",
    "# Usa o Optuna, um pacote Python para otimizar hiperparametros e o DBSCAN que é um algoritmo de aprendizado de máquina não supervisionado\n",
    "\n",
    "# Portanto, em nosso contexto, se uma transação é rotulada com o cluster -1, isso significa que ela não foi incluída em nenhum dos \n",
    "# clusters densos de transações formados pelo DBSCAN e foi considerada \"ruído\". Isso poderia potencialmente indicar uma transação incomum ou anômala, \n",
    "# dependendo do contexto específico e dos parâmetros do algoritmo.\n",
    "\n",
    "# Selecionando as colunas desejadas\n",
    "resultado = filtrado[['ID_Conta', 'Valor', 'Cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49cb057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o resultado em disco\n",
    "resultado.to_csv('transacoes_suspeitas.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c412fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fim\n",
    "# o arquivo foi gerado na mesma pasta no Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35963b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
